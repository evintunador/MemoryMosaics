{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8178ba-2ea0-4f4f-b9ca-c3435a83bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918a651-5c6a-4a39-8b3e-a28259e4fd64",
   "metadata": {},
   "source": [
    "# Load a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c0ba50-83de-4ad7-b262-944e6d547ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928.456K parameters\n",
      "ModelConfig(dim=80, device='cpu', tokenizer='bpe_v1', vocab_len=8192, num_layers=4, second_resid_norm=False, num_heads=2, head_dim=40, max_seq_len=512, mm_bias=False, pmem_size=224, pmem_count=1, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06)\n",
      "Model(\n",
      "  (token_embedder): Embedding(8195, 80)\n",
      "  (layers): ModuleList(\n",
      "    (0-3): 4 x Layer(\n",
      "      (pre_context_norm): Norm()\n",
      "      (context): ContextMem(\n",
      "        (k_featurizer): KeyFeatureExtractor(\n",
      "          (W_k): Linear(in_features=80, out_features=80, bias=False)\n",
      "          (leaky_avg): LeakyAvg()\n",
      "        )\n",
      "        (v_featurizer): ValFeatureExtractor(\n",
      "          (W_v): Linear(in_features=80, out_features=80, bias=False)\n",
      "        )\n",
      "        (c_proj): Linear(in_features=80, out_features=80, bias=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (pre_persistent_norm): Norm()\n",
      "      (persistent): PersistentMem(\n",
      "        (k_featurizer): KeyFeatureExtractor(\n",
      "          (W_k): Linear(in_features=80, out_features=80, bias=False)\n",
      "          (leaky_avg): LeakyAvg()\n",
      "        )\n",
      "        (c_proj): Linear(in_features=80, out_features=80, bias=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_norm): Norm()\n",
      "  (criterion): CrossEntropyLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## pretrained model options:\n",
    "# a 1m parameter model sticking close to the defaults from the paper: 'MM_1m'\n",
    "name = 'MM_1m'\n",
    "\n",
    "from tools import load_model\n",
    "model, tokenizer, cfg = load_model(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c971fce-8b3e-4732-bd66-d5d2028025d6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a366b1fc-b620-45a0-8b42-71bdca18906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c202ea0-e64d-4367-a4a6-102756fe63b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once| |upon| |a| |ti|me|, |th|er|e| |was| |a| |boy| |na|me|d| |Tim|. \n"
     ]
    }
   ],
   "source": [
    "# take a look at the tokenizer\n",
    "prompt = \"Once upon a time, there was a boy named Tim. \"\n",
    "print(tokenizer.display(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5b13a76-50f8-48b6-b7cf-9097d307c6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key-value caching is not enabled for this model; memory_saver_div = 8 is useless\n",
      "Once upon a time, there was a boy named Tim. Tim liked to play with his friend, Sam. They liked to play with his friend, Sam, and Sam didn't know what to do.\n",
      "One day, Sam saw a big, red tail. Sam and Sam didn't know what the dog wanted to play with his friends. Sam liked the big dog with his friends had a big dog. The dog was happy to play with his friends and played with his friends all day. They played with his friends and played with his friends. Sam went to the ball with his friends and played with his friends would be careful what to do. He know what to do Sam to play with his friends were a big, red house and saw his friends played with his friends all day, and Sam played with his friends were happy to have fun. They had lots of fun. Sam learned that he didn't know what to do Sam and Sam played with his friends became friends.\n"
     ]
    }
   ],
   "source": [
    "output = generate(\n",
    "    prompt, \n",
    "    model, \n",
    "    tokenizer,\n",
    "    #max_gen_len = 100,\n",
    "    temperature = 0.7,\n",
    "    top_p = 0.9,\n",
    "    top_k = 32,\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114de8bf-ab76-460d-8c37-ebe368b47e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
